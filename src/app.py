import zipfile
from io import BytesIO

import joblib
import matplotlib.pyplot as plt
import numpy as np
import streamlit as st
from PIL import Image
from tensorflow.keras.models import load_model

from config import MODEL_DIR
from data_loader import load_and_preprocess_image
from streamlit_live_metrics_callback import StreamlitLiveMetricsCallback
from train import train_with_zip

st.set_page_config(page_title="üêæ Classificateur d'Images", layout="wide")


def load_trained_model(model_name='hybrid_final.keras'):
    model_path = MODEL_DIR / model_name
    classes_path = MODEL_DIR / 'class_indices.pkl'

    if not model_path.exists() or not classes_path.exists():
        return None, None

    try:
        model = load_model(str(model_path))
    except Exception as e:
        st.error(f"Erreur lors du chargement du mod√®le : {e}")
        return None, None
    class_indices = joblib.load(str(classes_path))
    idx2label = {v: k for k, v in class_indices.items()}
    return model, idx2label


def predict(image: Image.Image, model, idx2label):
    """Predict class, probability, and return output vector."""
    x = load_and_preprocess_image(image)
    preds = model.predict(x)[0]
    idx = np.argmax(preds)
    return idx2label[idx], float(preds[idx]), preds


def main():
    st.title(" Projet : Classification d'images")
    st.write(
        "Cette application permet :\n"
        "   1. d‚Äôentra√Æner un mod√®le sur un ZIP d‚Äôimages structur√©es,\n"
        "   2. de visualiser en temps r√©el l‚Äô√©volution des m√©triques,\n"
        "   3. de tester la classification sur une image au choix."
    )

    tab1, tab2, tab3 = st.tabs(["Entra√Ænement", "Validation", "Test"])

    with tab1:
        st.header("Configuration de l‚Äôentra√Ænement")
        uploaded_zip = st.file_uploader("S√©lectionnez un ZIP de dataset", type=["zip"])

        col1, col2 = st.columns(2)
        with col1:
            epochs = st.number_input("Nombre d'√©poques", min_value=1, max_value=50, value=10, step=1)
            batch_size = st.select_slider("Taille de batch", options=[8, 16, 32, 64, 128], value=32)
        with col2:
            lr = st.number_input("Learning Rate", min_value=1e-6, max_value=1e-2,
                                 value=1e-3, format="%.6f")
            val_split = st.slider("Fraction validation", 0.1, 0.5, 0.2, step=0.05)

        if uploaded_zip:
            z = zipfile.ZipFile(BytesIO(uploaded_zip.getvalue()))
            # On collecte le premier composant de chaque chemin (les dossiers racine)
            classes = sorted({
                path.split('/')[0]
                for path in z.namelist()
                if '/' in path and not path.endswith('/')
            })
            st.markdown("**Classes d√©tect√©es dans votre dataset :**")
            st.write("üî∏ " + "\nüî∏ ".join(classes))
            st.markdown("---")
            if st.button("D√©marrer l‚Äôentra√Ænement"):
                callback = StreamlitLiveMetricsCallback(total_epochs=epochs)
                zip_path = MODEL_DIR / "user_dataset.zip"
                with open(zip_path, "wb") as f:
                    f.write(uploaded_zip.getbuffer())

                # Train and get history + class names
                metrics, class_names = train_with_zip(
                    zip_path=zip_path,
                    epochs=epochs,
                    batch_size=batch_size,
                    lr=lr,
                    val_split=val_split,
                    extra_callbacks=[callback]
                )

                st.success("Entra√Ænement termin√© !")

    with tab2:
        st.header("Courbes de validation des m√©triques")
        acc_img = MODEL_DIR / "accuracy.png"
        prec_img  = MODEL_DIR / "precision.png"
        rec_img = MODEL_DIR / "recall.png"
        loss_img = MODEL_DIR / "loss.png"
        if acc_img.exists() and prec_img.exists() and rec_img.exists() and loss_img.exists():

            col1, col2 = st.columns(2)
            with col1:
                st.subheader("Exactitude (Accuracy)")
                st.image(str(acc_img), caption="Train & Validation Accuracy", use_container_width=True)

                st.subheader("Pr√©cision (Precision)")
                st.image(str(prec_img), caption="Train & Validation Precision", use_container_width=True)

            with col2:
                st.subheader("Rappel (Recall)")
                st.image(str(rec_img), caption="Train & Validation Recall", use_container_width=True)

                st.subheader("Perte (Loss)")
                st.image(str(loss_img), caption="Train & Validation Loss", use_container_width=True)
        else:
            st.info("Pas de m√©triques disponibles ‚Äì entra√Ænez d‚Äôabord un mod√®le.")

    with tab3:
        st.header("Tester une image")
        model, idx2label = load_trained_model()
        if model is None or idx2label is None:
            st.info("Aucun mod√®le entra√Æn√© disponible. Veuillez d'abord entra√Æner un mod√®le.")
        else:
            uploaded_img = st.file_uploader("T√©l√©versez une image (png/jpg/jpeg)", type=["png", "jpg", "jpeg"])
            if uploaded_img:
                img = Image.open(uploaded_img).convert("RGB")
                st.image(img, caption="Votre image", use_container_width=True)
                with st.spinner("Classification‚Ä¶"):
                    label, proba, preds = predict(img, model, idx2label)
                st.success(f"Classe pr√©dite : **{label}** ({proba * 100:.1f}% de confiance)")
                st.markdown("**Top 3 pr√©dictions :**")
                for i in preds.argsort()[-3:][::-1]:
                    st.write(f"- {idx2label[i]} : {preds[i] * 100:.1f}%")


if __name__ == "__main__":
    main()